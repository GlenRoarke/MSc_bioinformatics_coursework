billdepth_boxp + geom_boxplot()
# t- test to check the difference between the two means
pengs_T <- penguins %>%
##reset levels of the factor
mutate(species=as.character(species)) %>%
# returns a more detailed output
rstatix::t_test(bill_depth_mm ~species, detailed = T) %>%
# return the significance too
rstatix::add_significance()
pengs_T
knitr::kable(tibble(pengs_T))
# comparing aic for model overview
summary(glm_norm_sex)$aic
summary(glm_norm_bw)$aic
#cross of predictors species and sex
glm_norm_sex <- glm(bill_depth_mm ~ species * sex, data = penguins, family = "gaussian")
glm_norm_bw <- glm(bill_depth_mm ~ species * body_mass_g, data = penguins, family = "gaussian")
knitr::opts_chunk$set(echo = TRUE)
library(palmerpenguins)
data(package = 'palmerpenguins')
library("dplyr")
library("ggplot2")
library("rstatix")
library("ggpubr")
library("knitr")
library("performance")
library("interactions")
library("jtools")
library('fitdistrplus')
check_model(glm_norm_sex)
plot_summs(glm_norm_sex, plot.distributions = TRUE, inner_ci_level = .9)
# compare species and sex models
plot_summs(glm_norm_sex,glm_norm_bw,
model.names = c("Species & Sex", "Species")
,inner_ci_level = .9
, rescale.distributions = TRUE
)
# compare species and sex models
plot_summs(glm_norm_sex,glm_norm_bw,
model.names = c("Species & Sex", "Species & Body weight")
,inner_ci_level = .9
, rescale.distributions = TRUE
)
# Plot the interactions
# sex and species are both categorical variables
cat_plot(glm_norm_sex,
pred = species,
modx = sex)
library(vroom)
library(tidyverse)
library(ggplot2)
library("performance")
##load the fitdistrplus package
library(fitdistrplus)
bucket_data <- vroom::vroom("https://raw.githubusercontent.com/ExperimentalConservation/Bioinformatics_data/master/IBT/all_groups_data.csv")
head(bucket_data)
length(unique(bucket_data$Species))
grouped_data <- bucket_data %>%
dplyr::filter(Success > 0) %>%
dplyr::group_by(Group_name ,Bucket,Distance) %>%
dplyr::summarise(sumSpecies = length(unique(Species))) # counting the amount of unique species when applied in the summarize
# Visualise the data
plot_sp_sum <-  ggplot(data = grouped_data, aes(x = Distance, y = sumSpecies, col = as.factor(Bucket)))
# glm using inbuit function in ggplot
plot_sp_sum + geom_point() + stat_smooth(method = 'glm',
method.args = list(family = "poisson"),
se = T,
aes(fill= as.factor(Bucket))) +
geom_point() +
theme()
# poisson model
# y = species
# x distance
glm_poisson <- glm(sumSpecies ~ Distance,
##specify the data
data = grouped_data,
##specify the error structure
family = "poisson")
# poisson model
# x distance + bucket (factor)
glm_dis_buck <- glm(sumSpecies ~ Distance + as.factor(Bucket),
##specify the data
data = grouped_data,
##specify the error structure
family = "poisson")
check_model(glm_poisson)
check_model(glm_dis_buck)
plot(fitdist(grouped_data$sumSpecies, "norm"))
fit_pois <- fitdist(grouped_data$sumSpecies, "pois")
plot(fit_pois)
gofstat(fit_pois)
plot(fitdist(grouped_data$sumSpecies, "norm"))
fit_pois <- fitdist(grouped_data$sumSpecies, "pois")
plot(fit_pois)
gofstat(fit_pois)
##fit a nbinom to the data instead
fit_nbinom <- fitdist(grouped_data$sumSpecies,dist = 'nbinom')
##plot it out:
plot(fit_nbinom)
gofstat(fit_nbinom)
##fit a nbinom to the data instead
fit_nbinom <- fitdist(grouped_data$sumSpecies,dist = 'nbinom')
##plot it out:
plot(fit_nbinom)
##look at the model summary:
summary(m_mod1)
##fit a random intercept effects model
m_mod1 <- glmmTMB(sumSpecies ~
Bucket +
Distance +
Bucket:Distance +
(1|Group_name),
data=grouped_data,
family="nbinom1")
##look at the model summary:
summary(m_mod1)
##fit a random intercept effects model
m_mod1 <- glmmTMB(sumSpecies ~
Bucket +
Distance +
Bucket:Distance +
(1|Group_name),
data=grouped_data,
family="nbinom1")
head(grouped_data)
##fit a random intercept effects model
m_mod1 <- glmmTMB(sumSpecies ~
Bucket +
Distance +
Bucket:Distance +
(1|Group_name),
data=grouped_data,
family="nbinom1")
library("glmmTMB")
##fit a random intercept effects model
m_mod1 <- glmmTMB(sumSpecies ~
Bucket +
Distance +
Bucket:Distance +
(1|Group_name),
data=grouped_data,
family="nbinom1")
##look at the model summary:
summary(m_mod1)
##fit a random intercept effects model
m_mod1 <- glmmTMB(sumSpecies ~
Bucket +
Distance +
Bucket:Distance +
(1|Group_name),
data=grouped_data,
family="nbinom1")
library("MuMIn")
# how much variance does my model explain.
# there are marginal and conditional
#34%
r.squaredGLMM(m_mod1)
r.squaredGLMM?
?r.squaredGLMM
##look at the model summary:
summary(m_mod1)
### task  how much variance does my model explain? ###
# there are marginal and conditional
# marginal - represents the variance explained by fixed effects
# conditional - is interpreted as a variance explained by the entire model.
#34%
r.squaredGLMM(m_mod1)
##look at the model summary:
summary(m_mod1)
library(DHARMa)
install.packages("DHARMa")
library(DHARMa)
## simulate the residuals from the model
##setting the number of sims to 1000 (more better, according to the DHARMa help file)
m_mod2_sim <- simulateResiduals(m_mod1, n = 1000)
##plot out the residuals
plot(m_mod2_sim)
testDispersion(m_mod1)
# add in thrower to grouped data
grouped_data_thrower <- bucket_data %>%
dplyr::select(-Attempt) %>% # remove unique ID
#dplyr::filter(Success > 0) %>%
dplyr::group_by(Thrower,Group_name ,Bucket,Distance ) %>%
distinct(across()) %>%
dplyr::summarise(sumSpecies = sum(Success))
grouped_data_thrower
##fit a random effects model with nested random effects
m_mod2 <- glmmTMB(sumSpecies ~ Distance +
Bucket +
Distance:Bucket +
(1|Group_name/Thrower),
data=grouped_data_thrower,
family="nbinom1")
##look at the summary
summary(m_mod2)
##fit a random effects model with nested random effects
m_mod2 <- glmmTMB(sumSpecies ~ Distance +
Bucket +
Distance:Bucket +
(1|Group_name/Thrower),
data=grouped_data_thrower,
family="nbinom1")
##look at the summary
summary(m_mod2)
m_mod2_optim <- glmmTMB(sumSpecies ~ Distance +
Bucket +
Distance:Bucket +
(1|Group_name/Thrower),
data=grouped_data_thrower,
family="nbinom1",
##the control parameter specifying the optimizer to use:
control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
##look at the summary
summary(m_mod2_optim)
(parcomp <- cbind(nlminb=unlist(fixef(m_mod2)),
optim=unlist(fixef(mod2_optim))))
(parcomp <- cbind(nlminb=unlist(fixef(m_mod2)),
optim=unlist(fixef(m_mod2_optim))))
## scaling data - mean = 0 and sd = 1
# this is useful when the continuous predictor variables are on very different scales.
# e.g distance and bucket size (1-5)
m_mod_scaled <- glmmTMB(sumSpecies ~ scale(Distance) +
scale(Bucket) +
scale(Distance):scale(Bucket) +
(1|Group_name/Thrower),
data=grouped_data_thrower,
family="nbinom1",
##the control parameter specifying the optimizer to use:
control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
##look at the summary
summary(m_mod_scaled)
# this nicely compares models before and after optimization
(parcomp <- cbind(nlminb=unlist(fixef(m_mod2)),
optim=unlist(fixef(m_mod2_optim)),
scaled=unlist(fixef(m_mod_scaled))))
## simulate the residuals from the model
##setting the number of sims to 1000 (more better, according to the DHARMa help file)
m_mod_scaled_sim <- simulateResiduals(m_mod_scaled, n = 1000)
##plot out the residuals
plot(m_mod_scaled_sim)
m_mod_optim_sim <- simulateResiduals(m_mod2_optim, n = 1000)
## simulate the residuals from the model
##setting the number of sims to 1000 (more better, according to the DHARMa help file)
m_mod_scaled_sim <- simulateResiduals(m_mod_scaled, n = 1000)
m_mod_optim_sim <- simulateResiduals(m_mod2_optim, n = 1000)
## simulate the residuals from the model
##setting the number of sims to 1000 (more better, according to the DHARMa help file)
m_mod_scaled_sim <- simulateResiduals(m_mod_scaled, n = 1000)
##plot out the residuals
plot(m_mod_scaled_sim)
plot(m_mod_optim_sim)
par(mfrow=c(1,2)) # Change the panel layout to 2 x 2
plot(m_mod_scaled_sim)
plot(m_mod_optim_sim)
par(mfrow=c(2,2)) # Change the panel layout to 2 x 2
plot(m_mod_scaled_sim)
plot(m_mod_optim_sim)
par(mfrow=c(1,1)) # Change back to 1 x 1
par(mfrow=c(2,2)) # Change the panel layout to 2 x 2
plot(m_mod_scaled_sim)
par(mfrow=c(1,1)) # Change back to 1 x 1
par(mfrow=c(2,4)) # Change the panel layout to 2 x 2
plot(m_mod_scaled_sim)
par(mfrow=c(1,1)) # Change back to 1 x 1
##plot out the residuals
plot(m_mod_scaled_sim)
plot(m_mod_optim_sim)
##calcualte the r-squared
MuMIn::r.squaredGLMM(m_mod_optim_sim)
##calcualte the r-squared
r.squaredGLMM(m_mod_optim_sim)
##calcualte the r-squared
r.squaredGLMM(m_mod2_optim)
##calcualte the r-squared
MuMIn::r.squaredGLMM(m_mod2_optim)
MuMIn::r.squaredGLMM(m_mod2)
MuMIn::r.squaredGLMM(m_mod_scaled)
testDispersion(m_mod2_optim)
testDispersion(m_mod_scaled)
###try with the other parameterisation for nbinom:
nb2_mod <- update(m_mod_scaled, family="nbinom2")
##zero inflated version of these with zeros being attributed to number of threats:
Zi_nb1_mod <- update(m_mod_scaled, ziformula = ~Thrower)
View(Zi_nb1_mod)
##and we can also look at the zero inflated version of the poisson model:
Zi_ps_mod <- update(m_mod_scaled, ziformula = ~Thrower, family="poisson")
##compare the models
anova(m_mod_scaled,
nb2_mod,
Zi_nb1_mod,
Zi_ps_mod)
## test to see where there are outliers, in our case not significant so we dont need to worry
testOutliers(m_mod_scaled,
plot = TRUE)
## tests if the simulated dispersion is equal to the observed dispersion,
## again not significant so no need to worry
testDispersion(m_mod_scaled,
plot = TRUE)
##compare the models, good for comparing AIC values
anova(m_mod_scaled,
m_mod2_optim,
nb2_mod,
Zi_nb1_mod,
Zi_ps_mod)
## test to see where there are outliers, in our case not significant so we dont need to worry
testOutliers(nb2_mod,
plot = TRUE)
## tests if the simulated dispersion is equal to the observed dispersion,
## again not significant so no need to worry
testDispersion(nb2_mod,
plot = TRUE)
## compares the distribution of expected zeros in the data against the observed zeros
## this is right on the borderline of being significant, suggesting there might be a better structure for
## our zero inflation parameter (remember we used ~n.threats). That might be worth looking into further
testZeroInflation(nb2_mod,
plot = TRUE)
## see if there is temporal autocorrelation in the residuals
testTemporalAutocorrelation(my_model,
time = ?,
## add in the predicted values from the model:
grouped_data_thrower$predicted <- predict(m_mod_scaled,
data = by_thrower,
type = "response")
## add in the predicted values from the model:
grouped_data_thrower$predicted <- predict(m_mod2_optim,
data = by_thrower,
type = "response")
## add in the predicted values from the model:
grouped_data_thrower$predicted <- predict(m_mod2_optim,
data = grouped_data_thrower,
type = "response")
##plot the predicted against the observed
ggplot(grouped_data_thrower, aes(x = number_of_species,
y = predicted)) +
geom_point(col="grey") +
geom_abline(slope = 1) +
theme_minimal() +
xlab("Observed") +
ylab("Predicted")
head(grouped_data_thrower)
## add in the predicted values from the model:
grouped_data_thrower$predicted <- predict(m_mod2_optim,
data = grouped_data_thrower,
type = "response")
head(grouped_data_thrower)
##plot the predicted against the observed
ggplot(grouped_data_thrower, aes(x = sumSpecies,
y = predicted)) +
geom_point(col="grey") +
geom_abline(slope = 1) +
theme_minimal() +
xlab("Observed") +
ylab("Predicted")
summary(m_mod2_optim)
install.packages("broom.mixed")
install.packages("dotwhisker")
library(broom.mixed)
library(dotwhisker)
## reshape the outputs of the model into a tidy format:
tidied_model_data <- broom.mixed::tidy(m_mod2_optim, conf.int = TRUE) %>%
##clean up the random effect names
mutate(term=ifelse(grepl("sd__(Int",term,
fixed=TRUE),
paste(group,term,sep="."),
term))
View(tidied_model_data)
head(m_mod2_optim)
head(m_mod2_optim)
View(m_mod2_optim)
View(tidied_model_data)
?ggplot
ggplot(data = tidied_model_data, aes( y = term, x = estimate) )
plot_coeff <- ggplot(data = tidied_model_data, aes( y = term, x = estimate) )
plot_coeff + geom_point()
plot_coeff + geom_point() + geom_errorbar()
plot_coeff + geom_point() + geom_errorbar(aes(xmin = estimate))
plot_coeff + geom_point() + geom_errorbar(aes(xmin = estimate, xmax =estimate))
plot_coeff + geom_point() + geom_errorbar(aes(xmin = min(estimate), xmax = max(estimate)))
?geom_errorbar
plot_coeff + geom_point() + geom_errorbar(aes(xmin = estimate, xmax = estimate))
plot_coeff + geom_point() + geom_errorbar(aes(xmin = estimate-std.error, xmax = estimate+ std.error))
plot_coeff + geom_point() + geom_errorbar(aes(xmin = estimate-conf.low, xmax = estimate+ conf.high))
##filter and sort the data
sorted_res_broom_thrower <-
res_broom_thrower %>%
filter(effect=="fixed") %>%
filter(term!="(Intercept)") %>%
mutate(term=factor(term, levels = rev(term)))
##filter and sort the data
sorted_res_broom_thrower <-
tidied_model_data %>%
filter(effect=="fixed") %>%
filter(term!="(Intercept)") %>%
mutate(term=factor(term, levels = rev(term)))
sorted_res_broom_thrower
##plot it out
ggplot(tidied_model_data, aes(x=estimate, y=term)) +
geom_errorbar(aes(xmin=conf.low, xmax=conf.high),
width=0.3,
col="grey50",
alpha=0.7) +
geom_point(col="coral", size=5, alpha=0.9) +
geom_vline(xintercept=0, lty="dashed", alpha=0.3) +
theme_bw() +
ylab("") +
xlab("Coefficient estimate")
##plot it out
ggplot(sorted_res_broom_thrower, aes(x=estimate, y=term)) +
geom_errorbar(aes(xmin=conf.low, xmax=conf.high),
width=0.3,
col="grey50",
alpha=0.7) +
geom_point(col="coral", size=5, alpha=0.9) +
geom_vline(xintercept=0, lty="dashed", alpha=0.3) +
theme_bw() +
ylab("") +
xlab("Coefficient estimate")
##load ggeffects
library(ggeffects)
#We may want to visulise the predicted values.
install.packages(ggeffects)
#We may want to visulise the predicted values.
install.packages("ggeffects")
##load ggeffects
library(ggeffects)
##predict the Distance and Bucket effects
my_df <- ggpredict(res_broom_thrower_mod, terms=c("Distance", "Bucket"))
##predict the Distance and Bucket effects
my_df <- ggpredict(sorted_res_broom_thrower, terms=c("Distance", "Bucket"))
##predict the Distance and Bucket effects
my_df <- ggpredict(sorted_res_broom_thrower, terms=c("Distance", "Bucket"))
##predict the Distance and Bucket effects
my_df <- ggpredict(tidied_model_data, terms=c("Distance", "Bucket"))
##predict the Distance and Bucket effects
my_df <- ggpredict(m_mod2_optim, terms=c("Distance", "Bucket"))
##plot the results!
plot(my_df) +
ylab("Number of Species") +
ggtitle("")
# predict how big an island would need to be to have 5 species at a distance of 2.5
ggpredict(res_broom_thrower_mod,
terms=c("Distance [250]", "Bucket [37]"))
# predict how big an island would need to be to have 5 species at a distance of 2.5
ggpredict(m_mod2_optim,
terms=c("Distance [250]", "Bucket [37]"))
# predict how big an island would need to be to have 5 species at a distance of 2.5
ggpredict(m_mod2_optim,
terms=c("Distance [5]", "Bucket [10]"))
# predict how big an island would need to be to have 5 species at a distance of 2.5
ggpredict(m_mod2_optim,
terms=c("Distance [250]", "Bucket [37]"))
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")
library("ggplot2")
library("rstatix")
library("ggpubr")
library("knitr")
library("performance")
library("interactions")
library("jtools")
library(palmerpenguins)
data(package = 'palmerpenguins')
##load Wes Anderson colour package
library(wesanderson)
install.packages("wesanderson")
library(wesanderson)
##load Wes Anderson colour package
library(wesanderson)
##load j tools
library(jtools)
##load interactiosn
library(interactions)
##load the preformance package
library(performance)
##load in the penguins package and data
library(palmerpenguins)
data("penguins")
##remove any NA values
penguins <- na.omit(penguins)
##visualise the data
ggplot(penguins, aes(x=species, y=flipper_length_mm, fill=sex, col=sex)) +
geom_boxplot(alpha = 0.3, outlier.shape=NA)+
geom_point(position=position_jitterdodge()) +
theme_classic() +
scale_fill_manual(values = wes_palette("Royal1"))+
scale_color_manual(values = wes_palette("Royal1"))
##load the ggpubr library
library(ggpubr)
##visualise the distributions
ggqqplot(penguins, x="flipper_length_mm", color="sex", facet.by="species")
##build my model
pen_mod <- glm(flipper_length_mm~species*sex, data=penguins, family="gaussian")
##look at summary
summary(pen_mod)
##check the fit
check_model(pen_mod)
##plot the coefficients:
plot_summs(pen_mod)
##plot model out
cat_plot(pen_mod,
pred = species,
modx = sex,
plot.points = TRUE,
int.width = 0.95,
interval = TRUE,
point.shape = T,
robust = TRUE)
##build my model
pen_mod <- glm(flipper_length_mm~species*sex, data=penguins, family="gaussian")
##look at summary
summary(pen_mod)
source("C:/Users/fh22528/Genome Biology/GBG_exam/Prokka_GhostKoala_join.R", echo=TRUE)
