{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43d0bb0-97cd-4f6e-a347-2c1f575dcaf4",
   "metadata": {},
   "source": [
    "# Supplementary Genome Biology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de29df4-b73d-497e-9d85-1391ada82c5b",
   "metadata": {},
   "source": [
    "This is a brief notebook to share examples of applying BASH, R and Python programming to genomic workflows. This is not a step by step command-line procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c9f91-feb8-4570-9d70-f0fca68883ef",
   "metadata": {},
   "source": [
    "## 1 Trimmomatic loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96261c87-e1ad-495a-860b-98422edc612d",
   "metadata": {},
   "source": [
    "This bash script reduces the manual nature for naming file input and outputs providing better reproducibility for the Trimmomatic software. The thread argument can be used to improve the speed of running with a HPC with multiple cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d5337-88d7-4843-ab98-e67a007553e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "```shell\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=trimmomatic\n",
    "#SBATCH --output=trimmomatic_out\n",
    "#SBATCH --error=trimmomatic_error\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=16\n",
    "#SBATCH --mem=10G\n",
    "#SBATCH --time=0-01:00:00\n",
    "#SBATCH --account=bisc029026\n",
    "\n",
    "#move into your current directory â€“ this will be named in the $SLURM_SUBMIT_DIR environment variable\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# arg1: number of threads\n",
    "# to run: \n",
    "# chmod +x trim.sh\n",
    "# <path>/trim.sh <number of threads>\n",
    "# Example: ./trim.sh 40\n",
    "\n",
    "for f in *_R1.fastq # for each sample\n",
    "\n",
    "do\n",
    "    n=${f%%_R1.fastq} # strip part of file name\n",
    "    java -jar /sw/apps/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads $1 ${n}_R1.fastq  ${n}_R2.fastq \\\n",
    "    ${n}_R1_trimmed.fastq.gz ${n}_R1_unpaired.fastq.gz ${n}_R2_trimmed.fastq.gz \\\n",
    "    ${n}_R2_unpaired.fastq.gz \\\n",
    "    LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15\n",
    "\n",
    "done\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc17cb-196c-4b9a-bcc9-d3a257f89c0b",
   "metadata": {},
   "source": [
    "Executed as\n",
    "```shell \n",
    "sbatch 01_GBG_trimm_loop.sh 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ed0ed-6985-44a4-bcda-5035f4f977a5",
   "metadata": {},
   "source": [
    "## 2 Fasta file Biopython Argparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59da923-1bbb-4b04-a08e-fe1ee60e4c0b",
   "metadata": {},
   "source": [
    "This python script provides a flexiable way to analyse and filter fasta files by sequence length on the command line without direct filepath calling. Future developments could include gene/protein calling and motif searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1303b1-b14c-406b-a199-14ebaafad9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the argparse module for better command line\n",
    "# no direct file paths are requried.\n",
    "\n",
    "# HPC required modules \n",
    "# module add lang/python/3.9.13\n",
    "# module add lang/python/anaconda/3.7-2019.03.biopython\n",
    "\n",
    "\n",
    "import argparse\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Create  argparse objects and define command line arguments\n",
    "parser = argparse.ArgumentParser(description='Filter a FASTA file to include only sequences longer than a specified length')\n",
    "parser.add_argument('input_file', type=str, help='input FASTA file')\n",
    "parser.add_argument('output_file', type=str, help='output FASTA file')\n",
    "parser.add_argument('-l', '--length', type=int, default=100, help='minimum length of selected sequences')\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Open the input and output files and filter the sequences\n",
    "count = 0\n",
    "total = 0\n",
    "with open(args.input_file, 'r') as input_handle, open(args.output_file, 'w') as output_handle:\n",
    "    for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "        total += 1\n",
    "        if len(record) >= args.length:\n",
    "            count += 1\n",
    "            SeqIO.write(record, output_handle, 'fasta')\n",
    "\n",
    "# Print\n",
    "print(f'{count} records selected out of {total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488a3a3-732a-45a4-a5c3-137d7789e1fd",
   "metadata": {},
   "source": [
    "Which can be executed on the command line as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee6f66-5273-4e60-a679-572e4825d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "python filter_contigs.py -l 1500 final.contigs.fa filtered_contigs_1500.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da296fe3-94fb-4559-aac6-812506c15457",
   "metadata": {},
   "source": [
    "## 3 R - Dplyr to join Prokka and Ghosta Koala data\n",
    "\n",
    "An example of an R script that joins taxonomic, structural and functional annotations together.\n",
    "This helps to filter sequences by taxonomy and compare genes between different genera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f84f5e-4d06-4737-82d2-e4993d1ac3f6",
   "metadata": {},
   "source": [
    "```R\n",
    "library(\"vroom\")\n",
    "library(\"tidyverse\")\n",
    "library(\"ggplot2\")\n",
    "\n",
    "#sets wd to location of rmd file R studio only not console\n",
    "setwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n",
    "\n",
    "#load in data from prokka and ghostKoala annotations\n",
    "prokka_data <- vroom(\"../GBG_exam/archaea_prokka/PROKKA_04032023.tsv\")\n",
    "\n",
    "ghost_koala <- vroom(\"../GBG_exam/GhostKoala_archaea/user.out.top\")\n",
    "\n",
    "ghost_annot <- vroom(\"../GBG_exam/GhostKoala_archaea/user_ko_definition.txt\")\n",
    "\n",
    "#tidy up the names\n",
    "col_names <- paste0(\"gtax_Column_\", 1:ncol(ghost_koala))\n",
    "colnames(ghost_koala) <- col_names\n",
    "\n",
    "\n",
    "col_names <- paste0(\"gann_Column_\", 1:ncol(ghost_annot))\n",
    "colnames(ghost_annot) <- col_names\n",
    "\n",
    "\n",
    "\n",
    "#View data\n",
    "head(prokka_data)\n",
    "head(ghost_koala)\n",
    "head(ghost_annot)\n",
    "\n",
    "#rename useful columns.\n",
    "ghost_koala <- ghost_koala %>% \n",
    "  rename(locus_tag = gtax_Column_1) %>% \n",
    "  rename(genus = gtax_Column_5)\n",
    "\n",
    "\n",
    "ghost_annot <- ghost_annot %>%\n",
    "  rename(locus_tag = gann_Column_1) %>% \n",
    "  rename(KEGG_annotation = gann_Column_3)\n",
    "\n",
    "\n",
    "\n",
    "# clean up - locus \n",
    "ghost_koala <- ghost_koala %>% \n",
    "  mutate(locus_tag = str_replace(locus_tag, \"user:\", \"\"))\n",
    "\n",
    "\n",
    "# join the three datasets via locus tag.\n",
    "joined_df <- inner_join(prokka_data, ghost_koala, by = \"locus_tag\") %>% \n",
    "             inner_join(ghost_annot, by = \"locus_tag\") %>% \n",
    "  select(locus_tag, ftype, genus, gene, EC_number, COG, product , KEGG_annotation, gtax_Column_3, gtax_Column_4)\n",
    "\n",
    "\n",
    "joined_df\n",
    "\n",
    "#write output to csv\n",
    "vroom_write(joined_df, \"joined_data.tsv\", delim = \"\\t\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d7a7f-bbc4-49c3-a146-68ca04200b68",
   "metadata": {},
   "source": [
    "## BUSCO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f86f2c-5f40-4977-9b44-87754caab726",
   "metadata": {},
   "source": [
    "An extra argument was added from the default to search prokaryotic databases only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa34fe2-a507-4d3e-a1cc-d02261ef251e",
   "metadata": {},
   "source": [
    "``` shell\n",
    "busco --in final.contigs.fa --mode genome  --auto-lineage-prok --out busco_results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c080a4c-9fbe-4750-beb0-1f85bd2c0785",
   "metadata": {},
   "source": [
    "# 4 Quast with read mapping\n",
    "Quast was run with the reference genome of c.p.syntrophicum, it would be interesting to also explore metaquast for metagenomic analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48540d4a-8bd7-492a-9c6b-3b68f4999cfc",
   "metadata": {},
   "source": [
    "``` shell\n",
    "\n",
    "#### Quast with a reference #####\n",
    "\n",
    "#download reference genome \n",
    "wget --timestamping https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/008/000/775/GCF_008000775.1_ASM800077v1/GCF_008000775.1_ASM800077v1_genomic.fna.gz -P cp_s_genome/\n",
    "\n",
    "#load quast\n",
    "module add lang/python/anaconda/3.8-2021-TW\n",
    "\n",
    "# quast without alignment\n",
    "quast.py final.contigs.fa -r cp_s_genome/GCF_008000775.1_ASM800077v1_genomic.fna.gz\n",
    "# run WITH alignment\n",
    "quast.py final.contigs.fa -r cp_s_genome/GCF_008000775.1_ASM800077v1_genomic.fna.gz --bam sort_cps_align.bam\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec69b9-71eb-4c76-a08f-3c1c9386f6f1",
   "metadata": {},
   "source": [
    "# 5 Read mapping the assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc2fbd-61e3-4e48-8d58-1f6341dd505d",
   "metadata": {},
   "source": [
    "To calculate the coverage of reads aligned to the assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ee749-96cb-4576-a7dc-081a681b3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BWA\n",
    "module load apps/bwa/0.7.17\n",
    "module load apps/samtools/1.9\n",
    "\n",
    "# Index the assembly file\n",
    "bwa index final.contigs.fa\n",
    "\n",
    "# Map the reads to the assembly\n",
    "bwa mem final.contigs.fa coursework2023_R1_trimmed.fastq coursework2023_R2_trimmed.fastq -o cps_align_trimmed.sam\n",
    "\n",
    "# Convert the SAM file to a BAM file\n",
    "samtools view -S -b cps_align_trimmed.sam > cps_align_trimmed.bam\n",
    "\n",
    "# Sort and index the BAM file\n",
    "samtools sort cps_align_trimmed.bam -o sort_cps_align_trimmed.bam\n",
    "samtools index sort_cps_align_trimmed.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1140f99-fdcb-42f2-a864-cd02b4df8e21",
   "metadata": {},
   "source": [
    "The mean coverage of the BAM file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a4432-8036-40a0-8219-d0d1a348b20b",
   "metadata": {},
   "source": [
    "```shell \n",
    "module load apps/samtools/1.9\n",
    "samtools depth sort_cps_align.bam -a  |  awk '{sum+=$3} END { print \"Average = \",sum/NR}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d16aa-0069-4fb6-92f3-56a49ffdf21e",
   "metadata": {},
   "source": [
    "Average =  15.434"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
